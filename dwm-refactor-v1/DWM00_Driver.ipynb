{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import DWM10_GetParms\n",
    "import DWM20_TokenizerFunctions\n",
    "import DWM25_Global_Token_Replace_NewDict ## added to import token replace code\n",
    "import DWM30_BuildRefList\n",
    "import DWM40_BuildBlocks\n",
    "import DWM50_IterateBlocks\n",
    "import DWM70_GeneratePairs\n",
    "import DWM80_TransitiveClosure\n",
    "import DWM90_IterateClusters\n",
    "import DWM97_ClusterProfile\n",
    "import DWM99_ERmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Washing Machine Refactor Version 1.4\n",
      "Enter Parameter File Name->S2-parms-nr.txt\n",
      "\n",
      ">> Starting DWM20\n",
      "Input Reference File Name = S2G.txt\n",
      "Input File has Header Records = True\n",
      "Input File Delimiter = ,\n",
      "Tokenizer Function Type = Splitter\n",
      "Remove Duplicate Reference Tokens = True\n",
      "Tokenized Reference Output File Name = S2G-Tokenized.txt\n",
      "\n",
      "Total References Read= 100\n",
      "Total Tokens Found = 1247\n",
      "Total Unique Tokens = 464\n",
      "\n",
      ">>Starting DWM30\n",
      "Total References Read from  S2G-Tokenized.txt = 100\n",
      "\n",
      ">>Starting Iterations\n",
      "mu start value= 0.5\n",
      "mu iterate value= 0.1\n",
      "epsilon start value= 3.5\n",
      "epsilon iterate value= 0.0\n",
      "comparator = Cosine\n",
      "\n",
      "****New Iteration\n",
      "Size of refList = 100 Size of linkIndex = 0\n",
      "\n",
      ">>Starting DWM40\n",
      "beta = 6\n",
      "sigma = 12\n",
      "Stop Words excluded= 391\n",
      "Total Blocking Records Created 564\n",
      "\n",
      ">>Starting DWM50\n",
      "Total Blocks Processed = 214\n",
      "Total Pairs in Compare Cache = 234\n",
      "\n",
      ">>Starting DWM70\n",
      "Total Pairs Linked = 54  at mu= 0.5\n",
      "\n",
      ">>Starting DWM80\n",
      "Total Closure Iterations = 2\n",
      "\n",
      ">>Starting DWM90\n",
      "Total Clusters Processed = 28\n",
      "Total Good Clusters = 22  at epsilon = 3.5\n",
      "Total References in Good Cluster = 50\n",
      "\n",
      ">>End of Iteration, Resetting mu and epsilon\n",
      ">>>New Value of mu =  0.6\n",
      ">>>New Value of epsilon =  3.5\n",
      "\n",
      "****New Iteration\n",
      "Size of refList = 50 Size of linkIndex = 50\n",
      "\n",
      ">>Starting DWM40\n",
      "beta = 6\n",
      "sigma = 12\n",
      "Stop Words excluded= 200\n",
      "Total Blocking Records Created 192\n",
      "\n",
      ">>Starting DWM50\n",
      "Total Blocks Processed = 91\n",
      "Total Pairs in Compare Cache = 76\n",
      "\n",
      ">>Starting DWM70\n",
      "Total Pairs Linked = 10  at mu= 0.6\n",
      "\n",
      ">>Starting DWM80\n",
      "Total Closure Iterations = 3\n",
      "\n",
      ">>Starting DWM90\n",
      "Total Clusters Processed = 5\n",
      "Total Good Clusters = 3  at epsilon = 3.5\n",
      "Total References in Good Cluster = 6\n",
      "\n",
      ">>End of Iteration, Resetting mu and epsilon\n",
      ">>>New Value of mu =  0.7\n",
      ">>>New Value of epsilon =  3.5\n",
      "\n",
      "****New Iteration\n",
      "Size of refList = 44 Size of linkIndex = 56\n",
      "\n",
      ">>Starting DWM40\n",
      "beta = 6\n",
      "sigma = 12\n",
      "Stop Words excluded= 182\n",
      "Total Blocking Records Created 153\n",
      "\n",
      ">>Starting DWM50\n",
      "Total Blocks Processed = 79\n",
      "Total Pairs in Compare Cache = 56\n",
      "\n",
      ">>Starting DWM70\n",
      "Total Pairs Linked = 4  at mu= 0.7\n",
      "\n",
      ">>Starting DWM80\n",
      "Total Closure Iterations = 4\n",
      "\n",
      ">>Starting DWM90\n",
      "Total Clusters Processed = 2\n",
      "Total Good Clusters = 1  at epsilon = 3.5\n",
      "Total References in Good Cluster = 2\n",
      "\n",
      ">>End of Iteration, Resetting mu and epsilon\n",
      ">>>New Value of mu =  0.8\n",
      ">>>New Value of epsilon =  3.5\n",
      "\n",
      "****New Iteration\n",
      "Size of refList = 42 Size of linkIndex = 58\n",
      "\n",
      ">>Starting DWM40\n",
      "beta = 6\n",
      "sigma = 12\n",
      "Stop Words excluded= 176\n",
      "Total Blocking Records Created 133\n",
      "\n",
      ">>Starting DWM50\n",
      "Total Blocks Processed = 75\n",
      "Total Pairs in Compare Cache = 43\n",
      "\n",
      ">>Starting DWM70\n",
      "Total Pairs Linked = 2  at mu= 0.8\n",
      "\n",
      ">>Starting DWM80\n",
      "Total Closure Iterations = 1\n",
      "\n",
      ">>Starting DWM90\n",
      "Total Clusters Processed = 2\n",
      "Total Good Clusters = 2  at epsilon = 3.5\n",
      "Total References in Good Cluster = 4\n",
      "\n",
      ">>End of Iteration, Resetting mu and epsilon\n",
      ">>>New Value of mu =  0.9\n",
      ">>>New Value of epsilon =  3.5\n",
      "\n",
      "****New Iteration\n",
      "Size of refList = 38 Size of linkIndex = 62\n",
      "\n",
      ">>Starting DWM40\n",
      "beta = 6\n",
      "sigma = 12\n",
      "Stop Words excluded= 153\n",
      "Total Blocking Records Created 110\n",
      "\n",
      ">>Starting DWM50\n",
      "Total Blocks Processed = 67\n",
      "Total Pairs in Compare Cache = 36\n",
      "\n",
      ">>Starting DWM70\n",
      "Total Pairs Linked = 0  at mu= 0.9\n",
      "Ending because pairList is empty\n",
      "Record written to S2G-LinkIndex.txt = 100\n",
      "\n",
      ">>Starting DWM97\n",
      "\n",
      "Cluster Profile\n",
      "Size\tCount\n",
      "1 \t 38 \t 38\n",
      "2 \t 22 \t 44\n",
      "3 \t 6 \t 18\n",
      "\tTotal\t 100\n",
      "\n",
      ">>Starting DWM99\n",
      "Truth File Name= truthABCgoodDQ.txt\n",
      "L= 40.0 E= 48.0 TP= 38.0\n",
      "Precision= 0.95\n",
      "Recall= 0.7917\n",
      "F-measure= 0.8637\n",
      "End of Program\n"
     ]
    }
   ],
   "source": [
    "# Main Driver for Refactored Data Washing Machine\n",
    "# Version 1.20 creates a log file with same information being written to console\n",
    "# Version 1.30 creates cluster profile at end of program and evaluates ER statistics\n",
    "# Version 1.40 FK - added module DWM25 to do global level token replacement\n",
    "#              JRT - added DWM65_ScoringMatrix to allow ScoringMatrix as a comparitor type\n",
    "version = 1.40\n",
    "# date time is used to label the logfile\n",
    "now = datetime.datetime.now()\n",
    "tag = str(now.year)+str(now.month)+str(now.day)+'_'+str(now.hour)+'_'+str(now.minute)\n",
    "logFile = open('DWM_Log_'+tag+'.txt','w')\n",
    "print(\"Data Washing Machine Refactor Version\",version)\n",
    "print(\"Data Washing Machine Refactor Version\",version, file=logFile)\n",
    "parmFileName = input('Enter Parameter File Name->')\n",
    "parms = DWM10_GetParms.getParms(parmFileName)\n",
    "tokenFreqDict = {}\n",
    "inputFileName = parms['inputFileName']\n",
    "periodIndex = inputFileName.rfind('.')\n",
    "inputPrefix = inputFileName[0:periodIndex]\n",
    "inputSuffix = inputFileName[periodIndex+1:]\n",
    "tokenizedFileName = inputPrefix+'-Tokenized.txt'\n",
    "DWM20_TokenizerFunctions.tokenizeInput(logFile, parms, tokenFreqDict, tokenizedFileName)\n",
    "#print(\"** Token Frequency Dictionary \\n\",tokenFreqDict)\n",
    "#Following read the parms for the global replacement code\n",
    "runReplacement = parms['runReplacement']\n",
    "minFreqStdToken = parms['minFreqStdToken']\n",
    "minLenStdToken = parms['minLenStdToken']\n",
    "maxFreqErrToken = parms['maxFreqErrToken']\n",
    "\n",
    "#if configured, Run global replacement\n",
    "if runReplacement:\n",
    "    DWM25_Global_Token_Replace_NewDict.globalReplace(logFile, inputPrefix, minFreqStdToken, minLenStdToken, maxFreqErrToken)\n",
    "    tokenizedFileName = inputPrefix+'-TokenReplace.txt' # define new global replaced file as input to be processed down stream\n",
    "refList = DWM30_BuildRefList.buildRefList(logFile, tokenizedFileName)\n",
    "moreToDo = True\n",
    "linkIndex =[]\n",
    "print('\\n>>Starting Iterations')\n",
    "print('\\n>>Starting Iterations', file=logFile)\n",
    "mu = parms['mu']\n",
    "print('mu start value=', mu)\n",
    "print('mu start value=', mu, file=logFile)\n",
    "muIterate = parms['muIterate']\n",
    "print('mu iterate value=', muIterate)\n",
    "print('mu iterate value=', muIterate, file=logFile)\n",
    "epsilon = parms['epsilon']\n",
    "print('epsilon start value=', epsilon)\n",
    "print('epsilon start value=', epsilon, file=logFile)\n",
    "epsilonIterate = parms['epsilonIterate']\n",
    "print('epsilon iterate value=', epsilonIterate)\n",
    "print('epsilon iterate value=', epsilonIterate, file=logFile)\n",
    "comparator = parms['comparator']\n",
    "print('comparator =', comparator)\n",
    "print('comparator =', comparator, file=logFile)\n",
    "\n",
    "while moreToDo:\n",
    "    print('\\n****New Iteration\\nSize of refList =', len(refList), 'Size of linkIndex =', len(linkIndex))   \n",
    "    print('\\n****New Iteration\\nSize of refList =', len(refList), 'Size of linkIndex =', len(linkIndex), file=logFile)  \n",
    "    blockList = DWM40_BuildBlocks.buildBlocks(logFile, refList, parms, tokenFreqDict)\n",
    "    if len(blockList)==0:\n",
    "        print('--Ending because blockList is empty')\n",
    "        print('--Ending because blockList is empty', file=logFile)\n",
    "        break\n",
    "    blockList.sort()\n",
    "    compareCache = DWM50_IterateBlocks.iterateBlocks(logFile, comparator, mu, blockList)\n",
    "    pairList = DWM70_GeneratePairs.generatePairs(logFile, mu, compareCache)\n",
    "    if len(pairList)==0:\n",
    "        print('Ending because pairList is empty')\n",
    "        print('Ending because pairList is empty', file=logFile)\n",
    "        break\n",
    "    clusterList = DWM80_TransitiveClosure.transitiveClosure(logFile, pairList)\n",
    "    if len(clusterList)==0:\n",
    "        print('--Ending because clusterList is empty') \n",
    "        print('--Ending because clusterList is empty', file=logFile)\n",
    "        break  \n",
    "    DWM90_IterateClusters.iterateClusters(logFile, epsilon, clusterList, refList, linkIndex)\n",
    "    print('\\n>>End of Iteration, Resetting mu and epsilon')\n",
    "    print('\\n>>End of Iteration, Resetting mu and epsilon', file=logFile)\n",
    "    mu += muIterate\n",
    "    mu = round(mu, 2)\n",
    "    print('>>>New Value of mu = ',mu)\n",
    "    print('>>>New Value of mu = ',mu, file=logFile)\n",
    "    epsilon += epsilonIterate\n",
    "    print('>>>New Value of epsilon = ',epsilon)\n",
    "    print('>>>New Value of epsilon = ',epsilon, file=logFile)\n",
    "    if mu > 1.0:\n",
    "        moreToDo = False\n",
    "        print('Ending because mu > 1.0')\n",
    "        print('Ending because mu > 1.0', file=logFile)\n",
    "# End of iterations\n",
    "# Add unclustered references to linkIndex\n",
    "for x in refList:\n",
    "    refID = x[1]\n",
    "    body = x[2]\n",
    "    newTuple = (refID, refID)\n",
    "    linkIndex.append(newTuple)\n",
    "# sort linkIndex by cluster IDs\n",
    "linkIndex.sort()\n",
    "# write out linkFile, but put RefID first and ClusterID second\n",
    "linkFileName = inputPrefix+'-LinkIndex.txt'\n",
    "linkFile = open(linkFileName,'w')\n",
    "linkFile.write('RefID, ClusterID\\n')\n",
    "for c in linkIndex:\n",
    "    linkFile.write(c[1]+','+c[0]+'\\n')\n",
    "linkFile.close()\n",
    "print('Record written to',linkFileName, '=',len(linkIndex))\n",
    "print('Record written to',linkFileName, '=',len(linkIndex), file=logFile)\n",
    "# Generate Cluster Profile\n",
    "profile = DWM97_ClusterProfile.generateProfile(linkIndex)\n",
    "print('\\nCluster Profile')\n",
    "print('\\nCluster Profile', file=logFile)\n",
    "print('Size\\tCount')\n",
    "print('Size\\tCount', file=logFile)\n",
    "total = 0\n",
    "for key in sorted(profile.keys()) :\n",
    "    clusterTotal = key*profile[key]\n",
    "    total +=clusterTotal\n",
    "    print(key, '\\t', profile[key], '\\t', clusterTotal)\n",
    "    print(key, '\\t', profile[key], '\\t', clusterTotal, file=logFile)\n",
    "print('\\tTotal\\t', total)\n",
    "print('\\tTotal\\t', total, file=logFile)\n",
    "# Generat ER Metrics if truthFileName was given\n",
    "if 'truthFileName' in parms:\n",
    "    truthFileName = (parms['truthFileName']).strip()\n",
    "    if len(truthFileName)>0:\n",
    "        DWM99_ERmetrics.generateMetrics(logFile, linkIndex, truthFileName)\n",
    "print(\"End of Program\")\n",
    "print(\"End of Program\", file=logFile)\n",
    "logFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
