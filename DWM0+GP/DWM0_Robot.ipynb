{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing References\n",
      "Total References= 1000\n",
      "Total Tokens Found = 13025\n",
      "Total Tokens Output = 12511\n",
      "Dictionary Load = 67077\n",
      "<class 'dict'>\n",
      "Global Replace Cycle\n",
      "Total References= 1000\n",
      "Total Tokens= 12511\n",
      "Unique Tokens= 3978\n",
      "Minimum Frequency of Standard Token =  5\n",
      "Minimum Length of Standard Token =  3\n",
      "Maximum Frequency of Error Token =  3\n",
      "References Processed= 1000\n",
      "Sorted Token Size = 3978\n",
      "Clean Token Size = 1776\n",
      "*Stop Replacements here\n",
      "References Processed =  1000\n",
      "Total Replacement Pairs = 240\n",
      "Tokens Read = 12511\n",
      "Tokens Changed =  256\n",
      "References Changed = 233\n",
      "\n",
      ">>>>>>>>>>>>\n",
      "Starting Iteration mu= 0.6\n",
      "Starting Iteration epsilon= 35\n",
      "Running NewMatrix Jar!\n",
      " Single-Reference Blocks = 1\n",
      "\n",
      " Multi-Reference Blocks = 1715\n",
      "NewMatrix Iterateblocks Total Time = 1.8763923990000002\n",
      "\n",
      "Precision = TP / (TP + FP) ......................... = 0.78797468\n",
      "Recall = TP / (TP + FN) ............................ = 0.88801712\n",
      "F-Measure .......................................... = 0.83501006\n"
     ]
    }
   ],
   "source": [
    "import DWM1_Tokenizer\n",
    "import DWM2_Global_Token_Replace_NewDict\n",
    "import DWM3_Entropy_Cluster\n",
    "# Settings for Tokenizer\n",
    "inputSampleName = r'S8'\n",
    "delimiter=','\n",
    "hasHeader = True\n",
    "tokenizerType = 'Splitter'\n",
    "removeDuplicateTokens = True\n",
    "\n",
    "# Setting for global replacement DWM2\n",
    "runReplacement = True\n",
    "minFreqStdToken = 5\n",
    "minLenStdToken = 3\n",
    "maxFreqErrToken = 3\n",
    "\n",
    "# Cluster Settings\n",
    "\n",
    "\n",
    "DWM1_Tokenizer.tokenizeCycle(inputSampleName, delimiter, hasHeader, removeDuplicateTokens, tokenizerType)\n",
    "prefixString = inputSampleName +','+tokenizerType+','+str(removeDuplicateTokens)\n",
    "fileToCluster = inputSampleName + '-Tokenized.txt'\n",
    "if runReplacement:\n",
    "    DWM2_Global_Token_Replace_NewDict.globalReplace(inputSampleName, minFreqStdToken, minLenStdToken, maxFreqErrToken)\n",
    "    fileToCluster = inputSampleName + '-TokenReplace.txt'\n",
    "    prefixString = prefixString+','+str(minFreqStdToken)+','+str(minLenStdToken)+','+str(maxFreqErrToken)\n",
    "else:\n",
    "    prefixString = prefixString+',0,0,0'\n",
    "\n",
    "# Cluster fixed settings\n",
    "muIterate = 0.1\n",
    "epsilonIterate = 0.0\n",
    "runClusterMetrics = False\n",
    "runFinalMetrics = True\n",
    "createFinalJoin = False\n",
    "\n",
    "# Cluster Robot Settings\n",
    "muStart = 0.60\n",
    "muEnd = 0.60\n",
    "muIncr = 0.05\n",
    "betaStart = 14\n",
    "betaEnd = 14\n",
    "betaIncr = 1\n",
    "sigmaStart = 145\n",
    "sigmaEnd = 145\n",
    "sigmaIncr = 1\n",
    "epsilonStart = 35\n",
    "epsilonEnd = 35\n",
    "epsilonIncr = 1\n",
    "mu = muStart\n",
    "while mu <= muEnd:\n",
    "    beta = betaStart\n",
    "    while beta <= betaEnd:\n",
    "        sigma = sigmaStart\n",
    "        while sigma <= sigmaEnd:\n",
    "            epsilon = epsilonStart\n",
    "            while epsilon <= epsilonEnd:\n",
    "                suffixString =','+str(epsilon)+','+str(epsilonIterate)\n",
    "                resultsList = DWM3_Entropy_Cluster.driver(fileToCluster, beta, sigma, mu, muIterate,epsilon,  \\\n",
    "                                                     epsilonIterate,runClusterMetrics, runFinalMetrics, createFinalJoin, hasHeader)\n",
    "                seg0a = ','+str(resultsList[0])+','+str(resultsList[1])+','+str(resultsList[2])+','+str(resultsList[3])\n",
    "                seg0b =','+str(resultsList[4])+','+str(resultsList[5])+','+str(resultsList[6])\n",
    "                seg1 = ','+str(beta)+','+str(sigma)+','+str(mu)+ ',' +str(muIncr)\n",
    "                seg2 = ','+str(resultsList[7])+','+str(resultsList[8])+','+str(resultsList[9])\n",
    "                outString = prefixString+seg0a+seg0b+suffixString+seg1+seg2+'\\n'\n",
    "                resultsFile = open('RobotResults.txt','a+')\n",
    "                resultsFile.write(outString)\n",
    "                resultsFile.close()\n",
    "                epsilon = epsilon + epsilonIncr\n",
    "            sigma = sigma + sigmaIncr\n",
    "        beta = beta + betaIncr\n",
    "    mu = mu + muIncr\n",
    "\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
